# -*- coding: utf-8 -*-
"""customer-churn-prediction-using-ann.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16G5lotlYyKMEDUVZzT3KIM080Hs2gqNU
"""

# Commented out IPython magic to ensure Python compatibility.
# necessary imports

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

plt.style.use('fivethirtyeight')
# %matplotlib inline

"""<p style = "font-size : 50px; color : #532e1c ; font-family : 'Comic Sans MS'; text-align : center; background-color : #bedcfa; border-radius: 5px 5px;"><strong>Churn Modelling Using ANN</strong></p>"""

df = pd.read_csv('/content/sample_data/Churn_Modelling.csv')
df.head()



df.describe()

df.info()

"""<p style = "font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;"><strong>Exploratory Data Analysis (EDA)</strong></p>"""

# checking for null values

df.isna().sum()

values = df.Exited.value_counts()
labels = ['Not Exited', 'Exited']

fig, ax = plt.subplots(figsize = (4, 3), dpi = 100)
explode = (0, 0.09)

patches, texts, autotexts = ax.pie(values, labels = labels, autopct = '%1.2f%%', shadow = True,
                                   startangle = 90, explode = explode)

plt.setp(texts, color = 'grey')
plt.setp(autotexts, size = 8, color = 'white')
autotexts[1].set_color('black')
plt.show()

"""<p style = "font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; "><strong>20% of the customers have churned and 80% haven't.</strong></p>"""

# visualizing categorical variables

fig, ax = plt.subplots(3, 2, figsize = (18, 15))

# The 'x' argument should be specified when using an Axes object with countplot
sns.countplot(x='Geography', hue = 'Exited', data = df, ax = ax[0][0])
sns.countplot(x='Gender', hue = 'Exited', data = df, ax = ax[0][1])
sns.countplot(x='Tenure', hue = 'Exited', data = df, ax = ax[1][0])
sns.countplot(x='NumOfProducts', hue = 'Exited', data = df, ax = ax[1][1])
sns.countplot(x='HasCrCard', hue = 'Exited', data = df, ax = ax[2][0])
sns.countplot(x='IsActiveMember', hue = 'Exited', data = df, ax = ax[2][1])

plt.tight_layout()
plt.show()

"""<p style = "font-size : 30px; color : #4e8d7c ; font-family : 'Comic Sans MS';"><strong>From above Plots we can conclude that:-</strong></p>

<ul>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>Majority of the customers are from france but most customers which churned are from germany maybe because of lack of resources as there are not many customers.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>The proportion of female customers churning is also greater than that of female customers.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>Majority of customers have tenure between 1 to 9 and churing rate is also high between these tenures.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>Most of the customers have 1 or 2 products and most customers which churned are having 1 products maybe they are not satisfied so they are churning.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>Interestingly, majority of customers that churned are those with credit cards but this can be a coincidence as majority of customers have credit cards.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>Unsurprisingly the inactive members have a greater churn and the overall proportion of inactive members is also very high.</strong></li>

"""

# visualizing continuous variables

fig, ax = plt.subplots(2, 2, figsize = (16, 10))

sns.boxplot(x = 'Exited', y = 'CreditScore', data = df, ax = ax[0][0])
sns.boxplot(x = 'Exited', y = 'Age', data = df, ax = ax[0][1])
sns.boxplot(x = 'Exited', y = 'Balance', data = df, ax = ax[1][0])
sns.boxplot(x = 'Exited', y = 'EstimatedSalary', data = df, ax = ax[1][1])

plt.tight_layout()
plt.show()

"""<p style = "font-size : 30px; color : #4e8d7c ; font-family : 'Comic Sans MS';"><strong>From above Plots we can conclude that:-</strong></p>

<ul>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>There is no significant difference in credit score distribution etween custers which are churned or not.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>The older customers are churning more than younger ones.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>Bank is loosing customers with significant bank balance.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>Estimated Salary does not have a significant on the likelihood to churn.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>Interestingly, majority of customers that churned are those with credit cards but this can be a coincidence as majority of customers have credit cards.</strong></li>
    <li style = "color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';"><strong>Unsurprisingly the inactive members have a greater churn and the overall proportion of inactive members is also very high.</strong></li>
"""

df.columns

"""<p style = "font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; "><strong>We can say that there is no multicolinearity present in data.</strong></p>"""

# dropping useless columns

df.drop(columns = ['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)
df.head()

df.Geography.value_counts()

# Encoding categorical variables

df['Geography'] = df['Geography'].map({'France' : 0, 'Germany' : 1, 'Spain' : 2})
df['Gender'] = df['Gender'].map({'Male' : 0, 'Female' : 1})

df.head()

# creating features and label

from tensorflow.keras.utils import to_categorical

X = df.drop('Exited', axis = 1)
y = to_categorical(df.Exited)

# splitting data into training set and test set

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)

# Scaling data

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""<p style = "font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;"><strong>Building ANN </strong></p>"""

import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import BatchNormalization

# initializing ann
model = Sequential()

# adding the first input layer and the first hidden layer
model.add(Dense(10, kernel_initializer = 'normal', activation = 'relu', input_shape = (10, )))

# adding batch normalization and dropout layer
model.add(Dropout(rate = 0.1))
model.add(BatchNormalization())

# adding the third hidden layer
model.add(Dense(7, kernel_initializer = 'normal', activation = 'relu'))

# adding batch normalization and dropout layer
model.add(Dropout(rate = 0.1))
model.add(BatchNormalization())

# adding the output layer
model.add(Dense(2, kernel_initializer = 'normal', activation = 'sigmoid'))

# compiling the model
model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

# fitting the model to the training set

model_history = model.fit(X_train, y_train, validation_split = 0.20, validation_data = (X_test, y_test), epochs = 50)

"""<p style = "font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;"><strong>Visualizing Training and Validation Loss</strong></p>"""

plt.figure(figsize = (12, 6))

train_loss = model_history.history['loss']
val_loss = model_history.history['val_loss']
epoch = range(1, len(train_loss) + 1) # Adjust epoch range to match data length
sns.lineplot(x=epoch, y=train_loss, label = 'Training Loss') # Use x and y keywords to specify data
sns.lineplot(x=epoch, y=val_loss, label = 'Validation Loss') # Use x and y keywords to specify data
plt.title('Training and Validation Loss\n')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""<p style = "font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;"><strong>Visualizing Training and Validation accuracy</strong></p>"""

plt.figure(figsize = (12, 6))

train_loss = model_history.history['accuracy']
val_loss = model_history.history['val_accuracy']
epoch = range(1, len(train_loss) + 1) # Adjust epoch range to match data length

# Pass data as a dictionary and specify x and y columns
sns.lineplot(x=epoch, y=train_loss, label = 'Training accuracy')
sns.lineplot(x=epoch, y=val_loss, label = 'Validation accuracy')

plt.title('Training and Validation Accuracy\n')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

acc = model.evaluate(X_test, y_test)[1]

print(f'Accuracy of model is {acc}')

model.summary()

from tensorflow.keras.utils import plot_model

plot_model(model, show_shapes = True)

"""<p style = "font-size : 25px; color : #f55c47 ; font-family : 'Comic Sans MS'; "><strong>If you like my work, please do Upvote.</strong></p>"""

